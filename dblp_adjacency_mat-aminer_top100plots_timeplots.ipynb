{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import math as m\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import model_selection\n",
    "import collections\n",
    "import re\n",
    "import networkx as nx\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = []\n",
    "with open('data/dblp-ref-0.json') as f:\n",
    "    for line in f:\n",
    "        data_json.append(json.loads(line))\n",
    "with open('data/dblp-ref-1.json') as f:\n",
    "    for line in f:\n",
    "        data_json.append(json.loads(line))\n",
    "with open('data/dblp-ref-2.json') as f:\n",
    "    for line in f:\n",
    "        data_json.append(json.loads(line))\n",
    "with open('data/dblp-ref-3.json') as f:\n",
    "    for line in f:\n",
    "        data_json.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['abstract'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parentdomain = {\n",
    "    \"coding theory\" : \"mathematical foundations\",\n",
    "    \"game theory\" : \"mathematical foundations\",\n",
    "    \"graph theory\" : \"mathematical foundations\",\n",
    "    \"mathematical logic\" : \"mathematical foundations\",\n",
    "    \"boolean logic\" : \"mathematical foundations\",\n",
    "    \"number theory\" : \"mathematical foundations\",\n",
    "    \"mathematical foundations\" : \"mathematical foundations\",\n",
    "    \"algorithms\" : \"algorithms and data structures\",\n",
    "    \"data structures\" : \"algorithms and data structures\",\n",
    "    \"algorithms and data structures\" : \"algorithms and data structures\",\n",
    "    \"automated reasoning\" : \"artificial intelligence\",\n",
    "    \"computer vision\" : \"artificial intelligence\",\n",
    "    \"machine learning\" : \"artificial intelligence\",\n",
    "    \"evolutionary computing\" : \"artificial intelligence\",\n",
    "    \"natural language processing\" : \"artificial intelligence\",    \n",
    "    \"artificial intelligence\" : \"artificial intelligence\",\n",
    "    \"neural network\" : \"artificial intelligence\",\n",
    "    \"speech processing\" : \"artificial intelligence\",\n",
    "    \"information retrieval\" : \"artificial intelligence\",\n",
    "    \"data mining\" : \"artificial intelligence\",\n",
    "    \"robotics\" : \"artificial intelligence\",\n",
    "    \"networking\" : \"communication and security\",\n",
    "    \"computer networks\" : \"communication and security\",\n",
    "    \"communication networks\" : \"communication and security\",\n",
    "    \"cryptography\" : \"communication and security\",\n",
    "    \"communication and security\" : \"communication and security\",\n",
    "    \"network protocols\" : \"communication and security\",\n",
    "    \"network attacks\" : \"communication and security\",\n",
    "    \"operating systems\" : \"computer architecture\",\n",
    "    \"computer architecture\" : \"computer architecture\",\n",
    "    \"image processing\" : \"computer graphics\",\n",
    "    \"information visualization\" : \"computer graphics\",\n",
    "    \"visualization\" : \"computer graphics\",\n",
    "    \"visualisation\" : \"computer graphics\",\n",
    "    \"computer graphics\" : \"computer graphics\",\n",
    "    \"parallel computing\" : \"concurrent, parallel, and distributed systems\",\n",
    "    \"concurrency\" : \"concurrent, parallel, and distributed systems\",\n",
    "    \"distributed computing\" : \"concurrent, parallel, and distributed systems\",\n",
    "    \"concurrent, parallel, and distributed systems\" : \"concurrent, parallel, and distributed systems\",\n",
    "    \"relational databases\" : \"databases\",\n",
    "    \"structured storage\" : \"databases\",\n",
    "    \"databases\" : \"databases\",\n",
    "    \"compiler theory\" : \"programming languages and compilers\",\n",
    "    \"programming language\" : \"programming languages and compilers\",\n",
    "    \"programming language pragmatics\" : \"programming languages and compilers\",\n",
    "    \"programming language theory\" : \"programming languages and compilers\",\n",
    "    \"formal semantics\" : \"programming languages and compilers\",\n",
    "    \"type theory\" : \"programming languages and compilers\",\n",
    "    \"programming languages and compilers\" : \"programming languages and compilers\",\n",
    "    \"computational science\" : \"scientific computing\",\n",
    "    \"numerical analysis\" : \"scientific computing\",\n",
    "    \"symbolic computation \" : \"scientific computing\",\n",
    "    \"computational physics\" : \"scientific computing\",\n",
    "    \"computational chemistry\" : \"scientific computing\",\n",
    "    \"bioinformatics\" : \"scientific computing\",\n",
    "    \"computational biology\" : \"scientific computing\",\n",
    "    \"computational neuroscience\" : \"scientific computing\",\n",
    "    \"scientific computing\" : \"scientific computing\",\n",
    "    \"formal methods\" : \"software engineering\",\n",
    "    \"algorithm design\" : \"software engineering\",\n",
    "    \"computer programming\" : \"software engineering\",\n",
    "    \"human–computer interaction\" : \"software engineering\",\n",
    "    \"reverse engineering\" : \"software engineering\",\n",
    "    \"software engineering\" : \"software engineering\",\n",
    "    \"automata theory \" : \"theory of computation\",\n",
    "    \"computability theory\" : \"theory of computation\",\n",
    "    \"computational complexity theory\" : \"theory of computation\",\n",
    "    \"quantum computing\" : \"theory of computation\",\n",
    "    \"theory of computation\" : \"theory of computation\",   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "def getdomainlist(row):\n",
    "    abst = row['abstract'] if type(row['abstract']) != float else  \"\"\n",
    "    venue = row['venue'] if type(row['venue']) != float else  \"\"\n",
    "    \n",
    "    text = abst + \" \" + row['title'] + \" \" + venue\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', ' ', text)\n",
    "    tokens = [token for token in text.split(\" \") if token != \"\"]\n",
    "    output1 = list(ngrams(tokens, 1))\n",
    "    output2 = list(ngrams(tokens, 2))\n",
    "    output3 = list(ngrams(tokens, 3))\n",
    "    output = []\n",
    "    for words in output1:\n",
    "        output.append(' '.join(words))\n",
    "    for words in output2:\n",
    "        output.append(' '.join(words))\n",
    "    for words in output3:\n",
    "        output.append(' '.join(words))\n",
    "    domainlist = set()\n",
    "    for word in output:\n",
    "        if word in parentdomain:\n",
    "            domainlist.add(parentdomain[word])\n",
    "    if len(domainlist) > 0:\n",
    "        return list(domainlist)[0]\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "df_copy['domain'] = df_copy.apply(getdomainlist, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffinal = df_copy[df_copy['domain'].map(lambda x: len(x) >0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/jet/var/python/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "dffinal['text'] = dffinal[['abstract', 'title', 'venue']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=10)]: Done 120 out of 120 | elapsed:  8.3min finished\n",
      "/jet/var/python/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        ...m_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=10,\n",
       "       param_grid={'vect__max_df': (0.5, 0.75, 1.0), 'vect__ngram_range': ((1, 1), (1, 2)), 'clf__max_iter': (5,), 'clf__alpha': (1e-05, 1e-06), 'clf__penalty': ('l2', 'elasticnet')},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dffinal['text'].head(40000), dffinal['domain'].head(40000), random_state = 0)\n",
    "\n",
    "pipeline = Pipeline([('vect', CountVectorizer(stop_words='english')),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge'))\n",
    "                     ])\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    # 'tfidf__use_idf': (True, False),\n",
    "    # 'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__max_iter': (5,),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    # 'clf__max_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5,n_jobs=10,\n",
    "                               verbose=1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(dffinal['text'].head(50000), dffinal['domain'].head(50000), random_state = 0)\n",
    "# class TextSelector(BaseEstimator, TransformerMixin):\n",
    "#     def __init__(self, field):\n",
    "#         self.field = field\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "#     def transform(self, X):\n",
    "#         return X[self.field]\n",
    "\n",
    "# def Tokenizer(str_input):\n",
    "#     words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "#     porter_stemmer=nltk.PorterStemmer()\n",
    "#     words = [porter_stemmer.stem(word) for word in words]\n",
    "#     return words\n",
    "\n",
    "# classifier = Pipeline([\n",
    "#             ('colext', TextSelector('text')),\n",
    "#             ('tfidf', TfidfVectorizer(tokenizer=Tokenizer, stop_words=\"english\",\n",
    "#                      min_df=.0025, max_df=0.25, ngram_range=(1,3))),\n",
    "#             ('svd', TruncatedSVD(algorithm='randomized', n_components=300)), #for XGB\n",
    "#     ('clf', XGBClassifier(max_depth=3, n_estimators=300, learning_rate=0.1)),\n",
    "# #    ('clf', RandomForestClassifier()),\n",
    "#     ])\n",
    "\n",
    "# parameters = {\n",
    "# #     'vect__max_df': (0.5, 0.75, 1.0),\n",
    "# #     # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "# #     'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "# #     # 'tfidf__use_idf': (True, False),\n",
    "# #     # 'tfidf__norm': ('l1', 'l2'),\n",
    "# #     'clf__max_iter': (5,),\n",
    "# #     'clf__alpha': (0.00001, 0.000001),\n",
    "# #     'clf__penalty': ('l2', 'elasticnet'),\n",
    "#     # 'clf__max_iter': (10, 50, 80),\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(clas, parameters, cv=5,n_jobs=10,\n",
    "#                                verbose=1)\n",
    "# grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df[['abstract', 'title', 'venue']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "753646"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = grid_search.predict(df['text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['domain'] = answer.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('domain', 'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3123\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3124\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlibindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3125\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.get_value_box\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-ccea85732988>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpidtod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'domain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6012\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6013\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6014\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6016\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-ccea85732988>\u001b[0m in \u001b[0;36mdomains\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpidtod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdomains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpidtod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'domain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3130\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3131\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3132\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3133\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3134\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/var/python/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 3118\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   3119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('domain', 'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "pidtod = {}\n",
    "def domains(row):\n",
    "    pidtod[row['id']] = row['domain']\n",
    "        \n",
    "x = df.apply(domains, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pidtoyear = {}\n",
    "def getyear(row):\n",
    "    pidtoyear[row['id']] = row['year']\n",
    "        \n",
    "x = df.apply(getyear, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "paperid = df['id'].values.tolist()\n",
    "papernames = df['title'].values.tolist()\n",
    "paperref = df['references'].values.tolist()\n",
    "paperidmap = {}\n",
    "paperidtoname = {}\n",
    "paperindextoid = {}\n",
    "g=nx.DiGraph()\n",
    "for index, i in enumerate(paperid):\n",
    "    paperidmap[i] = index\n",
    "    paperindextoid[index] = i\n",
    "    paperidtoname[i] = papernames[index]\n",
    "    \n",
    "ptop = {}\n",
    "for i in range(len(paperid)):\n",
    "    ptop[paperid[i]] = paperref[i]\n",
    "\n",
    "\n",
    "# for key in ptop.keys():\n",
    "#     t = set()\n",
    "#     if type(ptop[key]) == list:\n",
    "#         for i in ptop[key]:\n",
    "#             if i in paperidmap and pidtod[i] == pidtod[key]:\n",
    "#                 g.add_edge(paperidmap[key],paperidmap[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = nx.pagerank(g, alpha=0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "answer = sorted(pr.items(), key=lambda kv: kv[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic Algorithms in Search, Optimization and Machine Learning\n",
      "The Design and Analysis of Computer Algorithms\n",
      "A method for obtaining digital signatures and public-key cryptosystems\n",
      "Genetic programming: on the programming of computers by means of natural selection\n",
      "Christopher D. Manning and Hinrich Schutze. Foundations of Statistical Natural Language Processing . MIT Press, 2000. ISBN 0-262-13360-1. 620 pp. $64.95/£44.95 (cloth).\n",
      "Handbook of Applied Cryptography\n",
      "Minimizing the real functions of the ICEC'96 contest by differential evolution\n",
      "Term-weighting approaches in automatic text retrieval\n",
      "Differential Evolution – A Simple and Efficient Heuristic for Global Optimization over Continuous Spaces\n",
      "Perceived usefulness, perceived ease of use, and user acceptance of information technology\n",
      "Integer and combinatorial optimization\n",
      "Solving multiclass learning problems via error-correcting output codes\n",
      "Network flows: theory, algorithms, and applications\n",
      "Boosting the margin: a new explanation for the effectiveness of voting methods\n",
      "An introduction to computational learning theory\n",
      "Data clustering: a review\n",
      "DESIGN AND SYNTHESIS OF SYNCHRONIZATION SKELETONS USING BRANCHING TIME TEMPORAL LOGIC\n",
      "Fundamentals of speech recognition\n",
      "SURF: speeded up robust features\n",
      "A Temporal Logic of Nested Calls and Returns\n",
      "A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting\n",
      "Modeling the Shape of the Scene: A Holistic Representation of the Spatial Envelope\n",
      "How to prove yourself: practical solutions to identification and signature problems\n",
      "Time, clocks, and the ordering of events in a distributed system\n",
      "Introduction to Information Retrieval\n",
      "Evaluating collaborative filtering recommender systems\n",
      "Composite Texture Descriptions\n",
      "Determining optical flow\n",
      "Object detection by contour segment networks\n",
      "Fast Effective Rule Induction\n",
      "Statistical Language Learning\n",
      "Error control coding : fundamentals and applications\n",
      "Learning Logical Definitions from Relations\n",
      "Kernel Methods for Pattern Analysis\n",
      "Efficient algorithms for discovering association rules\n",
      "Okapi at TREC–3\n",
      "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond\n",
      "Communication and concurrency\n",
      "Interference Alignment and Degrees of Freedom of the $K$ -User Interference Channel\n",
      "An analysis of Bayesian classifiers\n",
      "Separating non-stationary from stationary scene components in a sequence of real world TV-images\n",
      "Messy genetic algorithms: motivation, analysis, and first results\n",
      "Soft Margins for AdaBoost\n",
      "AUTOMATIC SEARCH TERM VARIANT GENERATION\n",
      "A niched Pareto genetic algorithm for multiobjective optimization\n",
      "Improved approximation algorithms for maximum cut and satisfiability problems using semidefinite programming\n",
      "Mining quantitative association rules in large relational tables\n",
      "An evaluation of term dependence models in information retrieval\n",
      "Towards a Better Understanding of Context and Context-Awareness\n",
      "Concurrency control and recovery in database systems\n",
      "A study of cross-validation and bootstrap for accuracy estimation and model selection\n",
      "Comparative Experiments on Disambiguating Word Senses: An Illustration of the Role of Bias in Machine Learning\n",
      "Face recognition: A literature survey\n",
      "Irrelevant Features and the Subset Selection Problem\n",
      "Online computation and competitive analysis\n",
      "Gaussian Processes for Machine Learning\n",
      "A Comparison of Affine Region Detectors\n",
      "Bagging, boosting, and C4.S\n",
      "The String-to-String Correction Problem\n",
      "Understanding Computers and Cognition: A New Foundation for Design\n",
      "Fast Pattern Matching in Strings\n",
      "A simple derivation of the coding theorem and some applications\n",
      "Textural Features Corresponding to Visual Perception\n",
      "A Maximum Likelihood Approach to Continuous Speech Recognition\n",
      "The Definition of Standard ML\n",
      "Parameter Selection in Particle Swarm Optimization\n",
      "Efficient Asymmetric Self-Enforcement Scheme with Public Traceability\n",
      "A Complexity Measure\n",
      "The media equation: how people treat computers, television, and new media like real people and places\n",
      "Supervised and Unsupervised Discretization of Continuous Features.\n",
      "Statistical Comparisons of Classifiers over Multiple Data Sets\n",
      "Acoustic Modeling Using Deep Belief Networks\n",
      "We are family: joint pose estimation of multiple persons\n",
      "Matrix multiplication via arithmetic progressions\n",
      "Energy conserving routing in wireless ad-hoc networks\n",
      "On power-law relationships of the Internet topology\n",
      "An Empirical Analysis of Design Choices in Neighborhood-Based Collaborative Filtering Algorithms\n",
      "Blobworld: a System for Region-based Image Indexing and Retrieval\n",
      "Eliciting better information need descriptions from users of information search systems\n",
      "Intelligence without reason\n",
      "Algorithms on Stings, Trees, and Sequences: Computer Science and Computational Biology\n",
      "New Algorithms for Fast Discovery of Association Rules\n",
      "Pivoted document length normalization\n",
      "Authoritative sources in a hyperlinked environment\n",
      "A new method for solving hard satisfiability problems\n",
      "The macroscopic behavior of the TCP congestion avoidance algorithm\n",
      "Readings in information visualization: using vision to think\n",
      "The temporal logic of branching time\n",
      "Connections with multiple congested gateways in packet-switched networks part 1: one-way traffic\n",
      "Semantic similarity in a taxonomy: an information-based measure and its application to problems of ambiguity in natural language\n",
      "Scatter/Gather: a cluster-based approach to browsing large document collections\n",
      "Generative programming: methods, tools, and applications\n",
      "Sparse bayesian learning and the relevance vector machine\n",
      "Polynomial Reconstruction Based Cryptography\n",
      "Technical Note Q-Learning\n",
      "Introduction to data mining\n",
      "Short Signatures from the Weil Pairing\n",
      "N degrees of separation: multi-dimensional separation of concerns\n",
      "A cubist approach to object recognition\n",
      "Secure Integration of Asymmetric and Symmetric Encryption Schemes\n"
     ]
    }
   ],
   "source": [
    "for elem in answer[:100]:\n",
    "    print(paperidtoname[paperindextoid[elem[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "top100papers = answer[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pidtocitationyears = {}\n",
    "for p in paperid:\n",
    "    year = pidtoyear[p]\n",
    "    if type(ptop[p]) == list: \n",
    "        for rp in ptop[p]:\n",
    "            if rp in paperidmap:\n",
    "                rid = paperidmap[rp]\n",
    "                if rid not in pidtocitationyears:\n",
    "                    pidtocitationyears[rid] = {}\n",
    "\n",
    "                if year not in pidtocitationyears[rid]:\n",
    "                    pidtocitationyears[rid][year] = 1\n",
    "                else:\n",
    "                    pidtocitationyears[rid][year] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349209 {2017: 116, 2013: 621, 2012: 649, 2011: 804, 2008: 834, 2001: 409, 2004: 581, 2005: 711, 2000: 358, 2010: 825, 2006: 745, 1998: 344, 1999: 296, 2002: 441, 1991: 22, 1992: 33, 2014: 533, 2009: 898, 1990: 18, 1996: 154, 2003: 517, 1997: 212, 2007: 873, 1994: 107, 2015: 428, 1993: 54, 2016: 326, 1995: 121, 1989: 5, 1988: 2}\n",
      "354312 {1987: 99, 1985: 76, 1993: 109, 2000: 91, 2002: 80, 2007: 69, 2012: 53, 1977: 34, 2014: 47, 1986: 71, 1983: 73, 2015: 40, 1998: 97, 2011: 60, 1996: 86, 1979: 60, 1988: 93, 1984: 86, 2013: 44, 1997: 97, 1994: 105, 1976: 37, 1990: 102, 2010: 82, 1980: 63, 2006: 73, 1992: 108, 1981: 70, 2003: 83, 2008: 75, 1995: 77, 2017: 11, 1989: 100, 2001: 86, 1978: 48, 1982: 45, 2009: 81, 2005: 98, 1999: 97, 2004: 87, 2016: 37, 1991: 106, 1975: 10, 1973: 1, 1974: 2}\n",
      "711061 {2003: 145, 2012: 194, 2005: 246, 2011: 222, 2013: 189, 2008: 229, 2009: 244, 2007: 231, 1992: 35, 1996: 52, 1990: 35, 2002: 119, 1998: 92, 2004: 207, 1985: 29, 2006: 229, 2014: 166, 1995: 50, 1999: 120, 2010: 209, 1988: 27, 2000: 115, 2001: 123, 1997: 75, 2015: 167, 2016: 116, 1991: 32, 1994: 38, 1987: 29, 1993: 45, 1986: 8, 1989: 23, 1983: 12, 1981: 5, 1978: 5, 1982: 11, 1984: 14, 1979: 5, 1980: 3, 2017: 40}\n",
      "281175 {1999: 79, 2005: 189, 2011: 286, 2012: 222, 2013: 201, 1992: 3, 2000: 87, 2008: 260, 2006: 183, 2014: 182, 2009: 285, 2010: 271, 2003: 131, 2007: 264, 2004: 157, 1998: 87, 1996: 17, 1995: 17, 2015: 189, 2002: 130, 2001: 92, 1994: 26, 2016: 139, 1997: 29, 1993: 3, 2017: 45}\n",
      "277551 {2001: 52, 2003: 102, 2010: 177, 2012: 160, 2004: 118, 2009: 201, 2013: 179, 2006: 176, 2007: 203, 2002: 81, 2011: 189, 2008: 211, 2014: 146, 2000: 21, 2005: 195, 2015: 145, 2016: 80, 2017: 19, 1999: 2}\n",
      "355715 {2010: 269, 2003: 182, 2005: 295, 2012: 163, 2000: 105, 2008: 264, 2006: 264, 2013: 183, 2011: 234, 2014: 127, 1999: 71, 2009: 260, 2004: 217, 2007: 264, 2002: 136, 2001: 136, 2016: 92, 2015: 107, 2017: 29, 1998: 47, 1997: 12, 1996: 1}\n",
      "345544 {2000: 3, 2015: 12, 2007: 6, 2010: 12, 2004: 1, 2003: 4, 2005: 6, 1998: 2, 2006: 9, 2001: 1, 2009: 12, 2008: 6, 1997: 3, 2013: 6, 1999: 3, 2014: 7, 2011: 8, 2012: 8, 2016: 5, 2017: 1}\n",
      "575633 {2012: 227, 2006: 175, 2011: 214, 2009: 216, 2014: 180, 2002: 78, 2000: 39, 2003: 85, 2004: 126, 2010: 199, 2013: 214, 2007: 186, 2001: 75, 2008: 174, 2005: 134, 1997: 11, 1991: 5, 1994: 11, 1999: 34, 2015: 217, 2016: 162, 2017: 47, 1998: 31, 1995: 16, 1990: 4, 1993: 10, 1992: 10, 1996: 13, 1989: 2, 1988: 1}\n",
      "314819 {2017: 163, 2011: 362, 2012: 377, 2010: 267, 2014: 390, 2013: 447, 2007: 108, 2009: 231, 2005: 58, 2015: 466, 2006: 86, 2004: 37, 2000: 5, 2003: 22, 2016: 480, 2008: 169, 2002: 5, 2001: 7, 1998: 1, 1999: 2}\n",
      "385713 {2002: 72, 2012: 492, 2010: 450, 2013: 544, 2011: 478, 2009: 409, 2014: 557, 2003: 145, 2007: 304, 2008: 299, 1995: 23, 2004: 140, 2006: 208, 1999: 29, 2017: 207, 2001: 43, 2005: 179, 1996: 23, 2015: 492, 2016: 453, 1992: 4, 2000: 48, 1997: 22, 1991: 5, 1993: 8, 1990: 1, 1994: 9, 1998: 15}\n",
      "497991 {2012: 101, 2004: 99, 2011: 113, 2000: 71, 2001: 57, 2006: 117, 2007: 120, 1998: 50, 2003: 77, 2002: 80, 2009: 138, 1997: 36, 2014: 96, 1999: 41, 2008: 141, 2005: 114, 2016: 89, 2015: 107, 2017: 33, 2010: 98, 2013: 90, 1995: 26, 1991: 10, 1993: 20, 1994: 27, 1996: 28, 1992: 12, 1990: 3, 1989: 1}\n",
      "360459 {1997: 9, 2013: 56, 2005: 52, 2012: 71, 2007: 64, 2006: 56, 2011: 80, 2002: 34, 2001: 31, 2014: 61, 2009: 75, 2008: 76, 2015: 59, 2016: 42, 1999: 8, 2010: 88, 1998: 19, 2004: 43, 1995: 2, 2003: 50, 2000: 16, 1996: 1, 2017: 18}\n",
      "569100 {2011: 193, 2009: 182, 2012: 139, 2014: 128, 2003: 113, 2013: 155, 2007: 186, 2008: 193, 2001: 67, 2000: 77, 2002: 88, 2010: 165, 1999: 32, 2006: 172, 2004: 120, 2005: 160, 2016: 117, 2015: 147, 2017: 41, 1998: 50, 1997: 31, 1996: 10, 1994: 4, 1995: 7, 1993: 2}\n",
      "556296 {2002: 53, 2013: 53, 2011: 46, 2012: 62, 2014: 41, 2008: 56, 2001: 40, 2007: 44, 2005: 58, 2004: 57, 2016: 31, 2015: 40, 2010: 59, 2003: 55, 2006: 51, 1997: 2, 2009: 67, 2000: 34, 1999: 26, 1998: 15, 2017: 13}\n",
      "176570 {1997: 15, 2013: 26, 2000: 24, 2010: 34, 2014: 22, 2012: 20, 2003: 36, 2004: 24, 2015: 33, 2009: 36, 2007: 33, 2011: 18, 2005: 28, 2001: 20, 2006: 34, 1998: 17, 1996: 8, 2008: 31, 1999: 16, 2016: 21, 2002: 22, 1994: 1, 1995: 1, 2017: 3}\n",
      "681100 {2013: 295, 2011: 308, 2007: 306, 2012: 313, 2001: 33, 2006: 222, 2009: 317, 2015: 260, 2008: 326, 2005: 189, 2010: 293, 2003: 98, 2014: 247, 2000: 2, 2002: 58, 2004: 137, 2016: 233, 2017: 82, 1999: 1}\n",
      "141909 {2013: 59, 2011: 56, 2005: 70, 2014: 64, 2012: 61, 2007: 70, 2000: 32, 2008: 65, 2009: 69, 2010: 49, 2004: 47, 2017: 9, 2015: 61, 2016: 41, 2006: 68, 2002: 42, 2003: 48, 2001: 52, 1997: 20, 1999: 44, 1998: 24, 1987: 2, 1996: 8, 1994: 4, 1990: 7, 1988: 2, 1995: 11, 1992: 4, 1985: 3, 1986: 3, 1982: 2, 1989: 3, 1991: 5, 1984: 3, 1983: 2}\n",
      "249837 {2008: 161, 2004: 163, 2011: 127, 2007: 163, 2014: 80, 2012: 104, 2003: 134, 1999: 52, 2002: 108, 2006: 172, 2013: 96, 2005: 137, 1996: 27, 1998: 63, 2009: 153, 2001: 91, 2000: 100, 2010: 147, 2015: 76, 2016: 64, 2017: 20, 1995: 11, 1997: 46, 1994: 8}\n",
      "360633 {2012: 426, 2013: 454, 2011: 399, 2014: 393, 2010: 316, 2015: 450, 2009: 180, 2008: 116, 2016: 365, 2017: 105, 2007: 47, 2006: 4}\n",
      "243550 {2014: 212, 2013: 295, 2007: 209, 2012: 334, 2011: 303, 2010: 286, 2004: 148, 2015: 37, 2008: 247, 2009: 304, 2005: 189, 2003: 71, 2006: 142, 2016: 12, 2017: 4}\n",
      "653818 {2012: 250, 2011: 231, 2010: 250, 2014: 162, 2013: 234, 2005: 127, 2009: 254, 2001: 45, 2008: 220, 2000: 27, 2006: 162, 2002: 68, 2007: 193, 2016: 200, 2015: 175, 2003: 76, 1999: 15, 1998: 8, 2004: 91, 2017: 61, 1997: 1}\n",
      "261195 {2014: 303, 2012: 242, 2011: 195, 2013: 271, 2008: 45, 2015: 351, 2016: 348, 2010: 143, 2006: 10, 2003: 6, 2005: 7, 2009: 92, 2007: 31, 2004: 11, 2017: 124, 2002: 4, 2001: 1}\n",
      "303483 {2013: 56, 2009: 61, 2010: 58, 1998: 18, 2006: 62, 2014: 40, 1990: 7, 2008: 66, 2004: 31, 2011: 41, 2007: 60, 2012: 28, 2015: 42, 2003: 28, 2016: 45, 1987: 3, 1988: 6, 1995: 13, 2002: 31, 1999: 25, 2001: 35, 1994: 5, 1997: 8, 2000: 24, 2005: 50, 1996: 11, 1989: 8, 1993: 7, 1991: 8, 1992: 7, 2017: 10}\n",
      "538549 {2004: 127, 2010: 174, 2007: 155, 1980: 7, 2014: 169, 2013: 166, 2000: 89, 1977: 2, 2009: 166, 2011: 188, 2006: 137, 2001: 117, 1985: 18, 2012: 154, 1993: 70, 2005: 143, 2003: 116, 2002: 122, 1995: 93, 1996: 76, 1997: 119, 1999: 110, 2015: 176, 2016: 161, 1994: 91, 1998: 98, 2008: 152, 1987: 33, 1991: 50, 1988: 34, 1990: 55, 1989: 48, 1983: 14, 1992: 64, 1986: 15, 1981: 6, 1984: 11, 1982: 14, 1978: 2, 1979: 2, 2017: 47}\n",
      "198864 {2011: 390, 2012: 404, 2013: 439, 2014: 483, 2010: 309, 2015: 524, 2017: 113, 2009: 193, 2007: 18, 2008: 69, 2016: 374}\n",
      "519895 {2014: 183, 2010: 155, 2006: 65, 2011: 178, 2008: 112, 2012: 210, 2013: 202, 2007: 119, 2009: 140, 2015: 181, 2016: 142, 2004: 13, 2005: 34, 2003: 3, 2017: 45}\n",
      "208995 {2010: 122, 2012: 115, 2011: 76, 2014: 24, 2013: 35, 2007: 95, 2006: 73, 2009: 97, 2008: 71, 2003: 27, 2004: 80, 2005: 84, 2015: 2, 2016: 1}\n",
      "283828 {2011: 156, 2007: 126, 2012: 149, 2010: 127, 2004: 71, 2009: 119, 2013: 152, 2014: 129, 2015: 118, 2017: 41, 1998: 63, 2016: 119, 2006: 112, 1993: 36, 1991: 34, 2003: 63, 1999: 52, 1997: 42, 2008: 129, 1992: 43, 1994: 53, 2000: 60, 2001: 55, 2005: 87, 2002: 60, 1988: 26, 1996: 51, 1984: 6, 1990: 31, 1995: 52, 1987: 11, 1985: 5, 1983: 5, 1989: 29, 1981: 1, 1986: 11, 1982: 3, 2018: 1}\n",
      "441148 {2012: 187, 2011: 130, 2014: 71, 2013: 97, 2008: 97, 2010: 199, 2009: 154, 2007: 85, 2015: 34, 2016: 19, 2006: 14, 2017: 4, 2005: 1}\n",
      "358583 {2003: 52, 2011: 99, 2007: 66, 2012: 113, 2010: 93, 1996: 6, 2001: 37, 2013: 96, 2006: 79, 2014: 79, 1997: 10, 1999: 33, 1998: 19, 2005: 57, 2002: 34, 2008: 73, 2016: 68, 2015: 79, 2009: 86, 2004: 44, 2000: 27, 2017: 24}\n",
      "699535 {2001: 20, 2004: 22, 1999: 17, 2002: 24, 1998: 28, 1995: 5, 1997: 14, 2000: 20, 2010: 11, 1996: 14, 2007: 16, 2015: 9, 2012: 4, 2003: 22, 2005: 14, 2006: 12, 2009: 10, 2011: 15, 2008: 8, 2016: 5, 2013: 7, 1994: 3, 2017: 1}\n",
      "203648 {1999: 43, 2000: 53, 2012: 73, 1998: 33, 1995: 19, 2003: 75, 2001: 50, 2013: 40, 2004: 62, 2011: 88, 2005: 86, 2016: 22, 2015: 42, 2006: 76, 1997: 26, 1990: 6, 2002: 51, 2008: 90, 2010: 95, 2009: 100, 2007: 78, 2014: 38, 1992: 6, 1991: 11, 1988: 7, 1987: 4, 1994: 15, 1986: 1, 1989: 3, 1993: 10, 1996: 13, 1985: 2, 2017: 6, 1984: 1}\n",
      "732016 {1994: 48, 2005: 32, 2014: 14, 1997: 38, 1992: 17, 1993: 26, 1998: 49, 2001: 31, 2011: 29, 2008: 28, 2003: 31, 2013: 16, 1991: 18, 1995: 29, 2012: 19, 2002: 34, 1996: 30, 1999: 28, 2010: 23, 2006: 23, 2015: 16, 2000: 29, 2009: 23, 2007: 26, 2004: 28, 2016: 9, 2017: 2}\n",
      "157592 {2014: 129, 2011: 234, 2006: 123, 2013: 138, 2012: 163, 2010: 198, 2007: 158, 2008: 147, 2005: 56, 2009: 201, 2015: 146, 2016: 97, 2004: 5, 2017: 43, 2002: 1}\n",
      "6815 {2002: 14, 1997: 9, 2004: 16, 1996: 13, 2011: 6, 2012: 7, 1998: 10, 2006: 12, 2007: 16, 2015: 2, 1999: 15, 2003: 23, 2001: 18, 2000: 7, 2009: 11, 2010: 10, 2005: 10, 2013: 7, 2008: 10, 1994: 1, 2014: 4, 1995: 3, 2016: 3}\n",
      "105021 {2001: 26, 2004: 54, 2012: 82, 2011: 81, 2002: 31, 2014: 63, 2003: 43, 2010: 84, 1998: 6, 2008: 86, 2013: 61, 2009: 106, 1995: 6, 2005: 72, 2000: 26, 2007: 92, 2015: 53, 2016: 44, 2006: 68, 1997: 6, 1999: 9, 1996: 6, 1994: 2, 2017: 14}\n",
      "251155 {2009: 204, 2007: 123, 2011: 216, 2008: 138, 2013: 183, 2012: 216, 2005: 77, 2014: 177, 2006: 107, 2016: 191, 2003: 28, 2004: 54, 2010: 184, 2015: 226, 2017: 75, 2002: 6}\n",
      "146065 {2013: 110, 2014: 99, 2000: 169, 2003: 163, 2004: 170, 2011: 154, 2008: 193, 2007: 180, 2015: 82, 2009: 196, 2005: 179, 1999: 120, 2002: 173, 2012: 132, 2016: 60, 2006: 167, 1995: 78, 2001: 137, 2010: 153, 2017: 16, 1992: 29, 1990: 17, 1997: 125, 1996: 79, 1998: 135, 1991: 19, 1994: 56, 1993: 56, 1989: 1}\n",
      "583270 {2010: 114, 2014: 193, 2011: 198, 2015: 193, 2012: 284, 2016: 170, 2017: 54, 2013: 267, 2008: 12, 2009: 54}\n",
      "345143 {2003: 23, 2013: 27, 2012: 21, 2011: 25, 1997: 10, 1998: 9, 2004: 26, 2010: 21, 2007: 29, 1996: 4, 2005: 34, 2015: 20, 2016: 16, 1999: 11, 2001: 9, 2002: 8, 2009: 28, 2008: 27, 2006: 23, 2000: 13, 1994: 5, 1995: 2, 2014: 21, 2017: 5}\n",
      "69317 {1977: 1, 1996: 2, 2005: 2, 1980: 1, 1979: 1, 1981: 2, 1989: 2, 1990: 1, 1985: 1, 1991: 1, 2003: 1, 1995: 1, 1984: 1, 1999: 1, 2014: 2, 2004: 2, 1993: 2, 2000: 1}\n",
      "336192 {2000: 12, 1999: 8, 2012: 19, 2014: 17, 1998: 16, 1991: 3, 2002: 17, 2008: 26, 2015: 14, 2006: 25, 2004: 25, 1990: 5, 2010: 21, 2009: 23, 1992: 6, 2005: 18, 2003: 21, 1997: 8, 2001: 9, 1994: 8, 2007: 33, 1996: 11, 2016: 13, 2013: 23, 2011: 19, 1995: 4, 1993: 1, 2017: 5}\n",
      "212911 {2012: 33, 2011: 31, 2008: 40, 2003: 20, 2013: 43, 2001: 10, 2010: 55, 2016: 16, 2015: 24, 2002: 18, 2009: 42, 2006: 45, 2007: 42, 2000: 8, 2004: 29, 1999: 3, 2005: 27, 2014: 28, 2017: 7}\n",
      "610556 {1994: 5, 2008: 2, 1999: 4, 2013: 2, 1993: 3, 1996: 4, 2001: 2, 1988: 4, 1989: 5, 1992: 4, 2014: 2, 1997: 1, 2006: 2, 1990: 2, 2005: 2, 1985: 3, 1991: 3, 1986: 1, 2010: 1, 2009: 1, 1987: 4, 2012: 1, 2003: 1, 2016: 1}\n",
      "434478 {2012: 42, 2013: 32, 2011: 34, 2014: 41, 2015: 21, 2016: 26, 2005: 23, 2009: 35, 2006: 27, 2004: 18, 2007: 46, 2001: 15, 2010: 38, 1998: 7, 2002: 13, 1999: 4, 2008: 41, 2003: 18, 1996: 3, 2000: 6, 2017: 11}\n",
      "626320 {2013: 84, 2012: 83, 2011: 73, 2007: 57, 2009: 58, 2006: 59, 2004: 37, 2005: 58, 2010: 68, 2015: 92, 2014: 78, 2016: 91, 2017: 32, 2002: 42, 1998: 22, 2008: 61, 2003: 38, 1999: 22, 1997: 14, 2000: 20, 2001: 33, 1996: 2, 1995: 3}\n",
      "742042 {2012: 25, 2008: 47, 2011: 28, 2007: 36, 2004: 40, 2009: 40, 2013: 21, 2006: 55, 1998: 17, 2003: 40, 1997: 10, 2001: 45, 2016: 18, 1999: 26, 2000: 24, 2010: 26, 2002: 37, 2005: 45, 2014: 19, 1996: 5, 2015: 15, 2017: 5}\n",
      "425396 {1994: 1, 2003: 2, 2002: 3, 2007: 1, 2006: 2, 1986: 1, 1998: 1, 2015: 2, 1988: 2, 1995: 1, 2012: 1, 2008: 1, 2005: 2, 1989: 1, 1992: 1, 2001: 1, 2010: 1}\n",
      "423229 {2012: 128, 2006: 81, 2013: 132, 2008: 89, 2014: 131, 2011: 119, 2007: 118, 2009: 112, 2003: 24, 2005: 72, 2010: 127, 2004: 46, 2015: 132, 2016: 84, 2001: 10, 2002: 12, 2000: 5, 2017: 20, 1999: 1}\n",
      "222465 {2001: 81, 2010: 59, 2003: 68, 2008: 73, 1995: 78, 2014: 51, 2006: 89, 2011: 61, 2007: 83, 2013: 49, 2002: 68, 2012: 45, 2004: 86, 1996: 84, 1997: 99, 2000: 78, 2009: 72, 1998: 73, 2005: 82, 1991: 56, 2016: 31, 2015: 48, 1992: 77, 1999: 67, 1988: 18, 1990: 45, 1993: 77, 1994: 74, 1989: 21, 1987: 7, 2017: 11}\n",
      "361615 {1997: 10, 2012: 159, 2008: 103, 2011: 128, 2003: 40, 2013: 177, 2004: 38, 2001: 19, 2000: 17, 2010: 118, 2015: 198, 2014: 175, 2007: 70, 2005: 43, 2016: 190, 2002: 21, 2009: 108, 2006: 59, 1999: 9, 1996: 4, 1998: 8, 2017: 87}\n",
      "386919 {2000: 9, 2006: 6, 1997: 10, 2004: 6, 2015: 4, 1999: 3, 2005: 4, 2002: 9, 2010: 3, 2003: 2, 1998: 3, 2014: 3, 2012: 2, 2001: 3, 2013: 4, 2016: 2, 2007: 2, 2009: 1}\n",
      "660778 {2011: 199, 2016: 125, 2009: 205, 2014: 157, 2013: 184, 2010: 219, 2012: 191, 2006: 187, 2008: 193, 2015: 142, 2007: 180, 2005: 136, 2004: 99, 2003: 31, 2002: 20, 2001: 1, 2017: 37, 2000: 1}\n",
      "343176 {2011: 49, 2013: 34, 2012: 43, 2004: 48, 2005: 57, 2007: 48, 1996: 15, 2006: 57, 2003: 36, 1998: 19, 2014: 39, 2000: 30, 2015: 34, 2008: 32, 1997: 26, 2009: 51, 1995: 9, 2010: 38, 1999: 17, 2002: 26, 1994: 5, 2001: 17, 2016: 27, 2017: 12}\n",
      "236622 {2012: 69, 2011: 57, 2007: 48, 2003: 50, 2008: 68, 2013: 71, 2001: 40, 2006: 60, 2009: 74, 2014: 57, 2010: 68, 2015: 52, 2016: 50, 2005: 55, 2004: 64, 1999: 13, 2002: 40, 2000: 32, 1998: 3, 1997: 2, 2017: 12}\n",
      "372349 {2011: 225, 2013: 245, 2012: 243, 2014: 301, 2010: 175, 2016: 249, 2007: 54, 2009: 153, 2015: 360, 2008: 97, 2006: 13, 2005: 1, 2017: 69}\n",
      "594801 {2011: 142, 2007: 84, 2012: 122, 2013: 115, 2009: 133, 2014: 84, 2015: 120, 2008: 106, 2010: 157, 2016: 87, 2017: 28, 2006: 43, 2005: 9, 2003: 1}\n",
      "483690 {2012: 29, 2003: 31, 2007: 30, 2005: 28, 1997: 6, 2002: 38, 2009: 28, 1998: 27, 2011: 24, 2001: 25, 2013: 31, 2004: 28, 2016: 16, 2015: 19, 1999: 33, 2000: 28, 2010: 30, 2006: 23, 2008: 30, 1996: 2, 2014: 15, 1995: 1, 2017: 3}\n",
      "512243 {2012: 37, 1993: 15, 2007: 47, 2006: 62, 2004: 48, 2008: 67, 2011: 54, 2001: 29, 2010: 51, 2014: 46, 2003: 43, 1995: 31, 2009: 67, 2013: 58, 2015: 45, 1994: 13, 1998: 27, 2000: 29, 2002: 40, 2005: 46, 1997: 16, 1980: 5, 1999: 16, 1991: 7, 1992: 11, 2016: 38, 1979: 5, 1996: 24, 1989: 6, 1975: 7, 1988: 9, 1982: 3, 1990: 10, 1986: 5, 1974: 1, 1977: 1, 1987: 7, 1978: 2, 1983: 3, 1985: 7, 1984: 1, 1981: 3, 1976: 2, 2017: 13}\n",
      "429328 {2011: 38, 1993: 30, 2008: 32, 2014: 21, 2010: 49, 2012: 29, 1998: 25, 1991: 16, 2003: 24, 2005: 42, 1992: 15, 2001: 38, 1999: 26, 2009: 39, 2015: 16, 2013: 29, 2000: 30, 2006: 45, 1997: 14, 2007: 38, 2002: 45, 2004: 27, 1996: 16, 1995: 18, 1994: 18, 1987: 6, 1990: 16, 2016: 13, 1989: 12, 1988: 15, 1986: 1, 2017: 4}\n",
      "626208 {2014: 40, 2012: 48, 2010: 55, 2009: 52, 2011: 46, 2013: 41, 1981: 5, 2008: 52, 2006: 34, 2003: 33, 1997: 17, 1985: 14, 1996: 15, 1998: 19, 2017: 21, 2000: 21, 2007: 45, 2005: 39, 2001: 22, 2004: 29, 2016: 48, 2015: 37, 2002: 25, 1999: 18, 1992: 20, 1991: 13, 1990: 13, 1993: 15, 1989: 12, 1994: 19, 1987: 7, 1980: 6, 1995: 20, 1979: 5, 1984: 5, 1988: 12, 1977: 4, 1976: 3, 1983: 6, 1986: 3, 1978: 2, 1982: 5, 1975: 1}\n",
      "692632 {2013: 12, 2000: 4, 2015: 14, 1999: 6, 2011: 10, 2006: 9, 2001: 2, 2010: 13, 2009: 10, 2007: 12, 2012: 18, 2005: 7, 1972: 1, 1987: 3, 1967: 5, 2014: 10, 1970: 1, 1977: 2, 1988: 1, 1997: 3, 1973: 3, 2003: 7, 1969: 2, 2008: 7, 1974: 5, 1981: 1, 1979: 2, 1993: 3, 1982: 1, 1966: 1, 2004: 4, 1998: 3, 1995: 2, 1968: 1, 2002: 3, 1994: 2, 1991: 1, 1986: 1, 2016: 9, 2017: 4}\n",
      "651209 {2013: 47, 1981: 1, 2009: 34, 2012: 37, 2002: 11, 2011: 29, 2014: 48, 2004: 24, 2005: 20, 1979: 1, 2003: 11, 2015: 38, 2016: 31, 2007: 29, 2006: 19, 1997: 3, 1998: 11, 2000: 13, 1999: 10, 2008: 30, 2001: 11, 1994: 3, 1984: 2, 2010: 26, 1996: 5, 1989: 4, 1993: 3, 1995: 1, 1986: 2, 1992: 2, 1990: 1, 1983: 2, 1982: 1, 1991: 1, 2017: 11}\n",
      "487706 {1998: 14, 2009: 14, 2013: 14, 1996: 34, 2000: 19, 2011: 11, 1995: 18, 1985: 6, 2001: 13, 2014: 10, 1987: 4, 1988: 4, 2005: 16, 1989: 9, 2004: 13, 1991: 8, 2006: 13, 2003: 9, 2012: 8, 2002: 12, 1999: 14, 1993: 13, 2010: 17, 1994: 24, 1997: 10, 2016: 10, 1984: 4, 1986: 5, 2015: 6, 2008: 6, 2007: 10, 1990: 13, 1992: 9}\n",
      "398884 {2001: 50, 1999: 63, 2014: 20, 2012: 28, 2004: 45, 2011: 24, 2008: 28, 2006: 56, 1993: 31, 2013: 17, 1997: 41, 2009: 37, 1998: 60, 2016: 12, 2015: 14, 2000: 48, 2005: 52, 2007: 44, 1995: 45, 2002: 52, 1994: 40, 2010: 32, 2003: 45, 1996: 32, 1991: 9, 1992: 27, 1990: 7, 1989: 2, 2017: 7}\n",
      "282731 {2011: 75, 2012: 69, 2013: 75, 2004: 18, 2015: 51, 2016: 42, 2008: 53, 2010: 73, 2007: 44, 2005: 28, 2014: 63, 2009: 88, 2006: 40, 2003: 12, 2002: 3, 1998: 1, 2017: 16}\n",
      "229950 {2004: 2, 2001: 2, 2006: 1, 2010: 2, 2002: 1}\n",
      "473656 {2012: 99, 2005: 46, 2011: 103, 2004: 39, 2007: 63, 2009: 79, 2014: 98, 1997: 18, 2013: 109, 2010: 87, 2008: 88, 2015: 106, 1994: 28, 1998: 35, 2006: 52, 1999: 30, 1993: 27, 1992: 26, 1991: 24, 1996: 29, 2003: 40, 2001: 32, 1995: 26, 1987: 11, 1979: 7, 2002: 25, 1988: 18, 2016: 125, 1989: 15, 2000: 35, 1978: 4, 1984: 21, 1985: 13, 1986: 5, 1981: 11, 1990: 17, 1983: 9, 1980: 4, 1982: 8, 2017: 32}\n",
      "404438 {2010: 87, 2011: 89, 2004: 45, 2012: 74, 2007: 76, 2003: 33, 2008: 66, 2013: 85, 2009: 84, 2014: 67, 2002: 29, 2015: 65, 2005: 66, 1999: 13, 2001: 22, 2006: 60, 2000: 17, 1997: 5, 1998: 6, 1996: 1, 2016: 62, 2017: 28}\n",
      "361180 {2014: 30, 2011: 36, 2013: 36, 2000: 16, 2005: 38, 2002: 26, 2007: 55, 2012: 46, 1996: 8, 1997: 22, 2006: 42, 1998: 19, 2010: 33, 2008: 52, 2015: 32, 2016: 30, 2004: 41, 2009: 47, 1999: 17, 2003: 31, 2001: 19, 1995: 3, 2017: 5}\n",
      "260491 {2014: 314, 2011: 227, 2012: 265, 2013: 329, 2009: 154, 2006: 14, 2008: 103, 2010: 200, 2015: 368, 2016: 359, 2017: 178, 2007: 31}\n",
      "692163 {2014: 101, 2013: 75, 2015: 100, 2016: 82, 2012: 21, 2011: 2, 2017: 24}\n",
      "297039 {2012: 365, 2014: 139, 2011: 100, 2013: 114, 2015: 17, 2010: 14, 2016: 15, 2017: 2}\n",
      "585786 {2003: 28, 2014: 41, 2002: 19, 2004: 30, 2012: 63, 2008: 50, 2007: 61, 2013: 51, 2016: 28, 2015: 31, 1997: 16, 2009: 58, 2006: 45, 1998: 23, 2000: 18, 2005: 36, 2001: 30, 2010: 66, 1991: 7, 1999: 16, 2011: 52, 1993: 9, 1994: 7, 1995: 10, 2017: 11, 1996: 11, 1992: 10, 1989: 3, 1990: 4}\n",
      "384591 {2003: 47, 2005: 87, 2012: 39, 2013: 35, 2007: 81, 2002: 42, 2015: 10, 2006: 84, 2009: 58, 2014: 13, 2010: 50, 2011: 36, 2004: 63, 2001: 17, 2008: 65, 2000: 2, 2016: 7, 2017: 3}\n",
      "564757 {2012: 137, 2011: 116, 2010: 103, 2006: 103, 2013: 111, 2014: 100, 2004: 106, 2007: 117, 2009: 99, 2005: 111, 2015: 92, 2016: 68, 2002: 52, 2008: 128, 2001: 33, 2003: 77, 2000: 10, 2017: 24, 1999: 1}\n",
      "117936 {2013: 33, 2004: 4, 2011: 29, 2009: 14, 2015: 20, 2014: 29, 2016: 18, 2008: 16, 2010: 20, 2006: 5, 2005: 2, 2012: 23, 2007: 10, 2017: 4}\n",
      "184197 {2006: 33, 2005: 37, 2007: 32, 2011: 7, 2016: 7, 2010: 12, 2001: 16, 2009: 20, 2004: 46, 1999: 3, 2008: 18, 2002: 32, 2003: 33, 2013: 4, 1998: 1, 2014: 4, 2012: 10, 2000: 6, 2015: 5, 2017: 5}\n",
      "702615 {2011: 2, 2012: 5, 2009: 4, 2014: 3, 2010: 9, 2015: 3, 2008: 3, 2013: 2, 2016: 2}\n",
      "353114 {2005: 28, 1998: 31, 1997: 26, 2001: 29, 2013: 8, 2010: 23, 2002: 34, 2003: 19, 2008: 26, 1994: 14, 2009: 20, 2000: 29, 1999: 25, 2007: 26, 2004: 25, 1996: 19, 1993: 8, 2006: 20, 2016: 3, 2011: 16, 1995: 23, 2014: 5, 2015: 5, 1992: 3, 1991: 2, 2012: 4, 2017: 1}\n",
      "663474 {2013: 89, 2014: 100, 2011: 110, 2012: 100, 2001: 40, 2007: 121, 2010: 135, 2008: 121, 2015: 88, 2009: 146, 2006: 143, 2005: 124, 2003: 98, 2016: 84, 2004: 105, 2000: 30, 2002: 85, 1998: 8, 1999: 12, 1997: 2, 2017: 23}\n",
      "107888 {2003: 23, 2013: 22, 2011: 28, 2002: 16, 2014: 33, 2012: 36, 2005: 32, 2004: 26, 2015: 25, 2010: 23, 1998: 5, 2007: 27, 2000: 12, 1999: 10, 2006: 24, 1997: 1, 2001: 17, 2009: 23, 2008: 19, 2017: 8, 2016: 12}\n",
      "742748 {2012: 32, 2004: 18, 2006: 36, 2014: 28, 2013: 21, 1997: 10, 2009: 24, 2011: 24, 2005: 36, 2007: 31, 2015: 14, 2003: 14, 2001: 16, 2002: 26, 2008: 38, 1998: 5, 2010: 21, 1999: 10, 2000: 16, 2016: 14, 2017: 1}\n",
      "597017 {2001: 49, 2004: 74, 2006: 60, 2013: 49, 2005: 84, 2010: 67, 2003: 59, 2012: 60, 2011: 64, 2007: 81, 2008: 76, 2002: 83, 2000: 38, 2015: 18, 2014: 37, 1999: 22, 2009: 86, 2016: 16, 1998: 8, 2017: 2}\n",
      "357804 {1993: 12, 2004: 30, 2011: 18, 1995: 11, 1997: 26, 2012: 17, 1996: 35, 2003: 30, 2002: 30, 1994: 22, 2005: 36, 2013: 20, 2000: 35, 1999: 30, 2007: 32, 2006: 19, 2008: 35, 1998: 27, 2009: 20, 2001: 30, 2014: 8, 2010: 23, 2015: 8, 2016: 6, 1992: 1, 2017: 3}\n",
      "669826 {2011: 27, 2008: 20, 2004: 55, 2006: 45, 2016: 26, 2015: 14, 2002: 42, 2003: 45, 2005: 53, 2000: 39, 2001: 40, 2007: 35, 1999: 22, 2010: 42, 2009: 28, 2017: 8, 1998: 7, 2013: 25, 2014: 21, 2012: 11}\n",
      "169131 {2011: 58, 2003: 41, 2013: 61, 2005: 58, 2012: 51, 2007: 70, 2008: 76, 2000: 25, 2004: 55, 2014: 47, 2006: 66, 2009: 69, 2010: 66, 2015: 56, 2002: 46, 2001: 29, 1999: 13, 2016: 32, 1998: 2, 2017: 9}\n",
      "739504 {1992: 5, 2014: 9, 2012: 2, 2009: 8, 2001: 5, 2002: 8, 2007: 8, 2005: 4, 2008: 10, 1996: 3, 2010: 7, 2003: 5, 1997: 3, 1987: 1, 2011: 7, 2006: 8, 1999: 2, 1998: 3, 2000: 3, 1993: 3, 1986: 2, 1990: 4, 2016: 3, 2013: 7, 1988: 1, 1995: 2, 1994: 2, 2015: 3, 2004: 4, 1984: 1, 1991: 3, 1985: 1, 1983: 1, 2017: 1}\n",
      "689593 {2006: 12, 2005: 6, 2002: 14, 2000: 17, 1998: 3, 2007: 10, 1999: 12, 2001: 16, 2011: 10, 2003: 13, 2004: 11, 2009: 8, 2010: 8, 1997: 3, 1991: 1, 2008: 3, 2014: 1, 2012: 1, 2013: 6, 1995: 2, 1994: 1, 1996: 1, 1993: 2, 1992: 1, 2016: 1}\n",
      "355492 {2006: 49, 2009: 70, 2002: 8, 2013: 62, 2007: 57, 2011: 64, 2012: 54, 2010: 72, 2004: 25, 2005: 27, 2008: 56, 2015: 43, 2001: 12, 2014: 49, 2016: 35, 2000: 4, 2003: 13, 1999: 1, 2017: 11}\n",
      "714065 {2012: 41, 2007: 47, 2000: 24, 2013: 25, 2011: 30, 2006: 56, 2004: 38, 2001: 21, 2003: 29, 2002: 30, 1994: 4, 2005: 50, 2009: 51, 1999: 29, 2015: 20, 1998: 23, 2008: 48, 2010: 38, 1997: 14, 2016: 10, 2014: 23, 1995: 4, 1993: 5, 1996: 6, 1992: 1}\n",
      "139088 {2012: 93, 2007: 83, 2011: 90, 2013: 56, 2009: 91, 2008: 67, 2005: 85, 2006: 85, 2003: 35, 2014: 62, 2002: 35, 2010: 84, 2004: 65, 2017: 6, 2016: 39, 2015: 55, 2001: 27, 2000: 3, 1999: 2}\n",
      "352038 {2015: 160, 2006: 73, 2011: 136, 2009: 103, 2014: 145, 2004: 43, 2012: 130, 2013: 122, 2016: 151, 2010: 112, 2017: 58, 2007: 82, 2008: 79, 2005: 45, 2003: 21, 2002: 5}\n",
      "160032 {2014: 58, 2012: 141, 2013: 79, 2010: 103, 2007: 113, 2011: 124, 2004: 65, 2008: 81, 2005: 93, 2000: 3, 2009: 120, 2006: 61, 2015: 7, 2016: 2, 2003: 17, 2002: 3, 2001: 6}\n",
      "245327 {2012: 70, 2000: 22, 2003: 26, 2011: 64, 2014: 46, 2005: 45, 1999: 13, 2015: 49, 2009: 54, 2016: 44, 2006: 32, 1998: 20, 1995: 12, 2002: 23, 1997: 11, 2001: 16, 2008: 37, 2010: 57, 2004: 22, 2007: 46, 1994: 7, 1993: 3, 2013: 55, 1996: 8, 1992: 1, 2017: 23}\n",
      "259819 {2011: 257, 2010: 199, 2013: 176, 2012: 229, 2015: 190, 2014: 202, 2006: 29, 2007: 87, 2009: 176, 2016: 121, 2008: 122, 2017: 50, 2003: 1, 2005: 5}\n",
      "340600 {2011: 58, 2013: 45, 2014: 48, 2009: 63, 2004: 46, 2005: 71, 2003: 25, 2006: 55, 2010: 55, 2008: 55, 2012: 56, 2015: 46, 2016: 47, 2002: 12, 2007: 73, 2017: 14}\n",
      "674988 {2004: 39, 2013: 30, 2011: 34, 2006: 63, 2012: 29, 2007: 48, 2014: 13, 2009: 45, 2015: 18, 2003: 40, 2002: 39, 2005: 54, 2000: 10, 1999: 1, 2010: 35, 2001: 23, 2008: 40, 2016: 11, 2017: 1}\n",
      "447117 {2000: 5, 2006: 4, 2011: 1, 2001: 4, 2002: 6, 2014: 1, 2008: 6, 2003: 3, 2004: 3, 2009: 1, 2012: 1, 1999: 3, 2013: 3, 2005: 2, 2007: 1, 2016: 1}\n",
      "702755 {2011: 23, 2013: 20, 2014: 11, 2012: 19, 2000: 8, 2005: 14, 2016: 28, 2015: 22, 2010: 17, 2006: 13, 2001: 12, 2004: 8, 2009: 16, 2002: 6, 2008: 19, 2003: 11, 2007: 18, 2017: 6}\n"
     ]
    }
   ],
   "source": [
    "for p in top100papers:\n",
    "    print(p[0], pidtocitationyears[p[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
